{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cooperative-motor",
   "metadata": {},
   "source": [
    "## BERT with custom classifier\n",
    "\n",
    "Reference\n",
    "  - [Multi Class Text Classification With Deep Learning Using BERT](https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613)\n",
    "  - [Sentiment Analysis with BERT and Transformers by Hugging Face using PyTorch and Python](https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/)\n",
    "\n",
    "\n",
    "What used?\n",
    "  * BertTokenizer\n",
    "  * BertModel\n",
    " \n",
    "BerModel returns hidden state output and pooled output. I add custom MLP with 1 hidden layer as classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-kuwait",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T11:40:51.945899Z",
     "start_time": "2021-05-18T11:40:51.930966Z"
    }
   },
   "source": [
    "### Requirement\n",
    "  * transformers == 4.6.0\n",
    "  * pytorch == 1.8.0\n",
    "  * numpy == 1.1.92\n",
    "  * pandas == 1.2.3\n",
    "  * tqdm == 4.60.0\n",
    "  * scikit-learn == 0.24.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-upset",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T11:44:14.460119Z",
     "start_time": "2021-05-18T11:44:14.451143Z"
    }
   },
   "source": [
    "<a id=\"Table\"></a>\n",
    "### Table\n",
    "  - [Import library](#Import)\n",
    "  - [Check train set](#Trainset)\n",
    "  - [Split train/validation set](#Split)\n",
    "  - [Tokenizer, Encoding data](#Encode)\n",
    "  - [Check output of BertModel](#Output)\n",
    "  - [Define custom classifier model](#Classifier)\n",
    "  - [Call custom classifier model, Data loaders](#Model)\n",
    "    - Can modify batch_size in this block\n",
    "  - [Optimizer & Scheduler](#Optim)\n",
    "    - Can modify epochs, lr, etc. in this block\n",
    "  - [Load pre-trained weight](#Load)\n",
    "    - Can load pre-trained weight. If you don't want pre-trained weight, please skip this block\n",
    "  - [Running model](#Run)\n",
    "    - Can use pre-trained parameters\n",
    "  - [Test & Submission](#Sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-discretion",
   "metadata": {},
   "source": [
    "<a id=\"Import\"></a>\n",
    "### Import library\n",
    "  - [Return to table](#Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defensive-alignment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:25.668294Z",
     "start_time": "2021-05-26T17:50:24.406223Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import BertForMaskedLM, BertModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hourly-fifteen",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:25.714505Z",
     "start_time": "2021-05-26T17:50:25.668632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use cuda\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print('Use', 'cuda' if USE_CUDA else 'cpu')\n",
    "device = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-moses",
   "metadata": {},
   "source": [
    "<a id=\"Trainset\"></a>\n",
    "### Check train set\n",
    "  - [Return to table](#Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "discrete-laundry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:25.744424Z",
     "start_time": "2021-05-26T17:50:25.715503Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train_final.csv')\n",
    "#train_df = pd.read_csv('./data/aug_train_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-auction",
   "metadata": {},
   "source": [
    "Number of dataset, label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adverse-kazakhstan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:25.774344Z",
     "start_time": "2021-05-26T17:50:25.745436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11539</th>\n",
       "      <td>11539</td>\n",
       "      <td>3</td>\n",
       "      <td>Although Frailty fits into a classic genre , i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11540</th>\n",
       "      <td>11540</td>\n",
       "      <td>1</td>\n",
       "      <td>Mediocre fable from Burkina Faso .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11541</th>\n",
       "      <td>11541</td>\n",
       "      <td>4</td>\n",
       "      <td>Like all great films about a life you never kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11542</th>\n",
       "      <td>11542</td>\n",
       "      <td>4</td>\n",
       "      <td>Those who are n't put off by the film 's auste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11543</th>\n",
       "      <td>11543</td>\n",
       "      <td>4</td>\n",
       "      <td>An ambitious movie that , like Shiner 's organ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Category                                           Sentence\n",
       "11539  11539         3  Although Frailty fits into a classic genre , i...\n",
       "11540  11540         1                 Mediocre fable from Burkina Faso .\n",
       "11541  11541         4  Like all great films about a life you never kn...\n",
       "11542  11542         4  Those who are n't put off by the film 's auste...\n",
       "11543  11543         4  An ambitious movie that , like Shiner 's organ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coordinate-creativity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:25.804399Z",
     "start_time": "2021-05-26T17:50:25.775342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    3109\n",
       "1    3015\n",
       "2    2210\n",
       "4    1734\n",
       "0    1476\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-comfort",
   "metadata": {},
   "source": [
    "<a id=\"Split\"></a>\n",
    "### Split train/validation set\n",
    "  - [Return to table](#Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "narrative-sympathy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:25.834765Z",
     "start_time": "2021-05-26T17:50:25.805294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>1402</td>\n",
       "      <td>1402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>2864</td>\n",
       "      <td>2864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>2100</td>\n",
       "      <td>2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>train</th>\n",
       "      <td>2953</td>\n",
       "      <td>2953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>train</th>\n",
       "      <td>1647</td>\n",
       "      <td>1647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Id  Sentence\n",
       "Category data_type                \n",
       "0        train      1402      1402\n",
       "         val          74        74\n",
       "1        train      2864      2864\n",
       "         val         151       151\n",
       "2        train      2100      2100\n",
       "         val         110       110\n",
       "3        train      2953      2953\n",
       "         val         156       156\n",
       "4        train      1647      1647\n",
       "         val          87        87"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_df.index.values,\n",
    "                                                  train_df.Category.values,\n",
    "                                                  test_size=0.05, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=train_df.Category.values)\n",
    "\n",
    "train_df.loc[X_train, 'data_type'] = 'train'\n",
    "train_df.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "train_df.groupby(['Category', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "colonial-reporter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:25.849824Z",
     "start_time": "2021-05-26T17:50:25.835764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = train_df.Category.unique()\n",
    "\n",
    "label_dict = {x:x for x in sorted(train_df['Category'].unique())}\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-candle",
   "metadata": {},
   "source": [
    "<a id=\"Encode\"></a>\n",
    "### Tokenizer, Encoding data\n",
    "  - [Return to table](#Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "funky-plenty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:33.110903Z",
     "start_time": "2021-05-26T17:50:25.850735Z"
    }
   },
   "outputs": [],
   "source": [
    "#Use below tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)\n",
    "\n",
    "#Encode train sentence\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    train_df[train_df.data_type=='train'].Sentence.values, #Sentence data\n",
    "    add_special_tokens=True,    #Encoded with special tokens relative to their model\n",
    "    return_attention_mask=True, #Return attention mask according to tokenizer defined by max_length att.\n",
    "    padding='longest',           #Padding!\n",
    "    #truncation=True,            \n",
    "    return_tensors='pt'         #Return torch tensor\n",
    ")\n",
    "\n",
    "#Encode validation sentence\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    train_df[train_df.data_type=='val'].Sentence.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding='longest', \n",
    "    #truncation=True, \n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "typical-peoples",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:33.125865Z",
     "start_time": "2021-05-26T17:50:33.112900Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "encoded_data_train has 3 keys:\n",
    "  *input_ids\n",
    "  *token_type_ids\n",
    "  *attention_mask\n",
    "\"\"\"\n",
    "\n",
    "#Input\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(train_df[train_df.data_type=='train'].Category.values)\n",
    "\n",
    "#Validation\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(train_df[train_df.data_type=='val'].Category.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-mouse",
   "metadata": {},
   "source": [
    "<a id=\"Output\"></a>\n",
    "### Check output of BertModel\n",
    "  - [Return to table](#Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "funny-entity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:35.352552Z",
     "start_time": "2021-05-26T17:50:33.126862Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "color-malawi",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:35.367513Z",
     "start_time": "2021-05-26T17:50:35.353549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-LRB- The film -RRB- tackles the topic of relationships in such a straightforward , emotionally honest manner that by the end , it 's impossible to ascertain whether the film is , at its core , deeply pessimistic or quietly hopeful .\n"
     ]
    }
   ],
   "source": [
    "print(train_df['Sentence'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alone-starter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:35.427353Z",
     "start_time": "2021-05-26T17:50:35.368510Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "                train_df['Sentence'][0],\n",
    "                add_special_tokens=True,\n",
    "                return_attention_mask=True,\n",
    "                padding='longest',        \n",
    "                return_tensors='pt')\n",
    "\n",
    "outputs = model(\n",
    "            input_ids=encoding['input_ids'],\n",
    "            attention_mask=encoding['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "killing-wisconsin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:35.442313Z",
     "start_time": "2021-05-26T17:50:35.428349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 56, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "regulation-motivation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:35.457285Z",
     "start_time": "2021-05-26T17:50:35.443310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['pooler_output'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-group",
   "metadata": {},
   "source": [
    "<a id=\"Classifier\"></a>\n",
    "### Define custom classifier model\n",
    "  - [Return to table](#Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "higher-thong",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:35.472246Z",
     "start_time": "2021-05-26T17:50:35.458283Z"
    }
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.drop1 = nn.Dropout(p=0.3)\n",
    "        self.fc1 = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size//2)\n",
    "        self.output = nn.Linear(self.bert.config.hidden_size//2,  n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        x = self.bert(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask)\n",
    "        x = self.drop1(x[1])\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-saying",
   "metadata": {},
   "source": [
    "<a id=\"Model\"></a>\n",
    "### Call custom classifier model, Data loaders\n",
    "  - [Return to table](#Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "academic-plasma",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:38.958451Z",
     "start_time": "2021-05-26T17:50:35.473243Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (drop1): Dropout(p=0.3, inplace=False)\n",
       "  (fc1): Linear(in_features=768, out_features=384, bias=True)\n",
       "  (output): Linear(in_features=384, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier(len(train_df.Category.unique()))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "similar-consistency",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:38.973489Z",
     "start_time": "2021-05-26T17:50:38.959449Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-finger",
   "metadata": {},
   "source": [
    "<a id=\"Optim\"></a>\n",
    "### Optimizer & Scheduler\n",
    "  - [Return to table](#Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "analyzed-bradley",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:50:38.988297Z",
     "start_time": "2021-05-26T17:50:38.974524Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=2e-5, \n",
    "                  eps=1e-8)\n",
    "                  \n",
    "epochs = 30\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-sherman",
   "metadata": {},
   "source": [
    "<a id=\"Load\"></a>\n",
    "### Load pre-trained weight\n",
    "  - [Return to table](#Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "indoor-result",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:51:46.920943Z",
     "start_time": "2021-05-26T17:51:46.632870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./model_save/SST_5_fine_tuning.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-playlist",
   "metadata": {},
   "source": [
    "<a id=\"Run\"></a>\n",
    "### Running model\n",
    "  - [Return to table](#Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "advance-block",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T17:51:47.626732Z",
     "start_time": "2021-05-26T17:51:47.544090Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    losses = []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        predictions.append(preds)\n",
    "        \n",
    "        loss = loss_fn(outputs, batch[2])\n",
    "        \n",
    "        correct_predictions += torch.sum(preds == batch[2])\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    return correct_predictions.double() / len(dataloader_validation.dataset), np.mean(losses), predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "pursuant-reconstruction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T18:25:55.600119Z",
     "start_time": "2021-05-26T17:51:48.631514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da40dd7e069543cdbf8343e1853da3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 1.2648113613225975\n",
      "Validation loss: 1.2305358132800541\n",
      "Valdation accuracy: 0.6643598615916955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 1.2634435680100244\n",
      "Validation loss: 1.2694944513810646\n",
      "Valdation accuracy: 0.6262975778546713\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 1.2443488261963813\n",
      "Validation loss: 1.2560692671182994\n",
      "Valdation accuracy: 0.6384083044982699\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 1.231275244026768\n",
      "Validation loss: 1.27684925375758\n",
      "Valdation accuracy: 0.6141868512110726\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 1.2146973837568877\n",
      "Validation loss: 1.246863361951467\n",
      "Valdation accuracy: 0.6487889273356402\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6\n",
      "Training loss: 1.196763584982202\n",
      "Validation loss: 1.220089293814994\n",
      "Valdation accuracy: 0.6695501730103807\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7\n",
      "Training loss: 1.1721491493914635\n",
      "Validation loss: 1.2043906579146515\n",
      "Valdation accuracy: 0.6920415224913495\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8\n",
      "Training loss: 1.1518370436162364\n",
      "Validation loss: 1.1948468926790599\n",
      "Valdation accuracy: 0.6972318339100346\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9\n",
      "Training loss: 1.136477275509876\n",
      "Validation loss: 1.1951947147781785\n",
      "Valdation accuracy: 0.7024221453287197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10\n",
      "Training loss: 1.1208097355185027\n",
      "Validation loss: 1.2046672798491813\n",
      "Valdation accuracy: 0.6920415224913495\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11\n",
      "Training loss: 1.1068883158548928\n",
      "Validation loss: 1.1735515433388788\n",
      "Valdation accuracy: 0.726643598615917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12\n",
      "Training loss: 1.0956439000524516\n",
      "Validation loss: 1.1811428182833903\n",
      "Valdation accuracy: 0.7162629757785467\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13\n",
      "Training loss: 1.088928842249139\n",
      "Validation loss: 1.1793369505856488\n",
      "Valdation accuracy: 0.7197231833910035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14\n",
      "Training loss: 1.0827846315094751\n",
      "Validation loss: 1.174507597008267\n",
      "Valdation accuracy: 0.7231833910034602\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15\n",
      "Training loss: 1.0771980551519478\n",
      "Validation loss: 1.1586108835967812\n",
      "Valdation accuracy: 0.7352941176470589\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16\n",
      "Training loss: 1.0733430465525857\n",
      "Validation loss: 1.1569118113131136\n",
      "Valdation accuracy: 0.740484429065744\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17\n",
      "Training loss: 1.07184822462043\n",
      "Validation loss: 1.15978868587597\n",
      "Valdation accuracy: 0.7370242214532872\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18\n",
      "Training loss: 1.0663793340716348\n",
      "Validation loss: 1.1548454278224223\n",
      "Valdation accuracy: 0.7439446366782008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19\n",
      "Training loss: 1.0615090885071992\n",
      "Validation loss: 1.1681647687344938\n",
      "Valdation accuracy: 0.7283737024221454\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20\n",
      "Training loss: 1.059039571542434\n",
      "Validation loss: 1.148788086465887\n",
      "Valdation accuracy: 0.7491349480968859\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21\n",
      "Training loss: 1.0586747680044035\n",
      "Validation loss: 1.155995646038571\n",
      "Valdation accuracy: 0.740484429065744\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22\n",
      "Training loss: 1.0540036704206606\n",
      "Validation loss: 1.151691729957993\n",
      "Valdation accuracy: 0.7422145328719724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23\n",
      "Training loss: 1.0539370081862625\n",
      "Validation loss: 1.143704672117491\n",
      "Valdation accuracy: 0.7525951557093425\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24\n",
      "Training loss: 1.0497988261738602\n",
      "Validation loss: 1.146609348219794\n",
      "Valdation accuracy: 0.7508650519031143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25\n",
      "Training loss: 1.047525461926057\n",
      "Validation loss: 1.1499378777839042\n",
      "Valdation accuracy: 0.7491349480968859\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26\n",
      "Training loss: 1.0465961009177105\n",
      "Validation loss: 1.138308323718406\n",
      "Valdation accuracy: 0.7612456747404844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27\n",
      "Training loss: 1.0454114719834342\n",
      "Validation loss: 1.1430042160523903\n",
      "Valdation accuracy: 0.7560553633217993\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28\n",
      "Training loss: 1.0445079667922708\n",
      "Validation loss: 1.144856515768412\n",
      "Valdation accuracy: 0.7525951557093425\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29\n",
      "Training loss: 1.042750497427348\n",
      "Validation loss: 1.1390803295212824\n",
      "Valdation accuracy: 0.7612456747404844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30:   0%|          | 0/686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30\n",
      "Training loss: 1.042096252170318\n",
      "Validation loss: 1.137437254995913\n",
      "Valdation accuracy: 0.759515570934256\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    losses = []\n",
    "\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, batch[2])\n",
    "        \n",
    "        correct_predictions += torch.sum(preds == batch[2])\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "         \n",
    "    #If you want to save model parameters, please modify below code.\n",
    "    #Line 80 save model for every epochs\n",
    "    #torch.save(model.state_dict(), f'data_volume/finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = np.mean(losses)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_acc, val_loss, _ = evaluate(dataloader_validation)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'Valdation accuracy: {val_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-jesus",
   "metadata": {},
   "source": [
    "<a id=\"Sub\"></a>\n",
    "### Test & Submission\n",
    "  - [Return to table](#Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "olympic-topic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T18:25:55.615053Z",
     "start_time": "2021-05-26T18:25:55.601090Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/eval_final_open.csv')\n",
    "test_df[\"Category\"] = np.zeros(test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afraid-holly",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T18:25:56.869820Z",
     "start_time": "2021-05-26T18:25:55.616050Z"
    }
   },
   "outputs": [],
   "source": [
    "#Encode test sentence\n",
    "encoded_data_test = tokenizer.batch_encode_plus(\n",
    "    test_df.Sentence.values, #Sentence data\n",
    "    add_special_tokens=True,    #Encoded with special tokens relative to their model\n",
    "    return_attention_mask=True, #Return attention mask according to tokenizer defined by max_length att.\n",
    "    padding='longest',           #Padding!\n",
    "    #truncation=True,            \n",
    "    return_tensors='pt'         #Return torch tensor\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(dataset_val, \n",
    "                             batch_size=batch_size)\n",
    "\n",
    "input_ids_test = encoded_data_test['input_ids']\n",
    "attention_masks_test = encoded_data_test['attention_mask']\n",
    "labels_test = torch.tensor(test_df.Category.values, dtype=int)\n",
    "\n",
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test,\n",
    "                             batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hundred-candle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T18:26:02.201636Z",
     "start_time": "2021-05-26T18:25:56.870818Z"
    }
   },
   "outputs": [],
   "source": [
    "_, _, predictions = evaluate(dataloader_test)\n",
    "pred = torch.cat([x for x in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "synthetic-season",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T18:26:02.231812Z",
     "start_time": "2021-05-26T18:26:02.201842Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"./data/sample_sub.csv\")\n",
    "sub['Category'] = pred.cpu()\n",
    "\n",
    "sub.to_csv(\"./data/210527_custom_pre_30_16.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
